// src/lib/ai-config.ts
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { streamText } from 'ai';
import { GoogleGenerativeAI } from '@google/generative-ai';

// ============================================================================
// 1. ZENTRALE MODELL-DEFINITION
// √Ñndere hier die Modelle, um sie im GESAMTEN Projekt zu aktualisieren.
// ============================================================================
export const AI_CONFIG = {
  primaryModel: 'gemini-3-flash-preview',
  fallbackModel: 'gemini-2.5-flash',
  
  settings: {
    strict: { temperature: 0.1 },  // F√ºr JSON / Daten
    balanced: { temperature: 0.7 }, // F√ºr Chat / Evita (Standard)
    creative: { temperature: 0.9 }, // F√ºr Marketing-Ideen
  }
};

// Initialisiere den Vercel AI SDK Client einmal zentral (f√ºr route.ts Dateien)
const google = createGoogleGenerativeAI({
  apiKey: process.env.GEMINI_API_KEY || '',
});

// ============================================================================
// 2. HELFER F√úR NEXT.JS ROUTEN (@ai-sdk/google)
// Ersetzt das manuelle try/catch in jeder Route
// ============================================================================
/**
 * F√ºhrt streamText automatisch mit dem Fallback-Mechanismus aus.
 * √úbergib einfach alle Parameter au√üer 'model'.
 */
export async function streamTextSafe(params: Omit<Parameters<typeof streamText>[0], 'model'>) {
  try {
    // Versuch 1: Prim√§res Modell (Gemini 3)
    // console.log(`ü§ñ AI-Manager: Nutze Primary (${AI_CONFIG.primaryModel})`);
    return streamText({
      ...params,
      model: google(AI_CONFIG.primaryModel),
    });
  } catch (error) {
    console.warn(`‚ö†Ô∏è AI-Manager: Primary (${AI_CONFIG.primaryModel}) fehlgeschlagen. Starte Fallback auf ${AI_CONFIG.fallbackModel}.`, error);
    
    // Versuch 2: Fallback Modell (Gemini 2.5)
    return streamText({
      ...params,
      model: google(AI_CONFIG.fallbackModel),
    });
  }
}

// ============================================================================
// 3. HELFER F√úR STANDARD SDK (ask-gemini.js)
// ============================================================================
/**
 * Gibt fertig konfigurierte Modell-Instanzen zur√ºck.
 * Nutze dies in ask-gemini.js
 */
export function getGeminiInstances(client: GoogleGenerativeAI) {
    const config = { temperature: AI_CONFIG.temperature };
    
    return {
        primary: client.getGenerativeModel({ model: AI_CONFIG.primaryModel, generationConfig: config }),
        fallback: client.getGenerativeModel({ model: AI_CONFIG.fallbackModel, generationConfig: config }),
        modelNames: {
            primary: AI_CONFIG.primaryModel,
            fallback: AI_CONFIG.fallbackModel
        }
    };
}
